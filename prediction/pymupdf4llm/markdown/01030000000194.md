Peihao Wang, Rameswar Panda, Lucas Torroba Hennigen, Philip Greengard, Leonid Karlinsky, Rogerio Feris, David Daniel Cox, Zhangyang Wang, and
Yoon Kim. 2023. Learning to grow pretrained models for efficient transformer training. _arXiv preprint_
_arXiv:2303.00980_ .


Yizhong Wang, Yeganeh Kordi, Swaroop Mishra, Alisa Liu, Noah A Smith, Daniel Khashabi, and Hannaneh Hajishirzi. 2022. Self-instruct: Aligning language model with self generated instructions. _arXiv_
_preprint arXiv:2212.10560_ .


Jason Wei, Maarten Bosma, Vincent Y Zhao, Kelvin
Guu, Adams Wei Yu, Brian Lester, Nan Du, Andrew M Dai, and Quoc V Le. 2021. Finetuned language models are zero-shot learners. _arXiv preprint_
_arXiv:2109.01652_ .


Jason Wei, Yi Tay, Rishi Bommasani, Colin Raffel,
Barret Zoph, Sebastian Borgeaud, Dani Yogatama,
Maarten Bosma, Denny Zhou, Donald Metzler, et al.
2022a. Emergent abilities of large language models.
_arXiv preprint arXiv:2206.07682_ .


Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten
Bosma, Fei Xia, Ed Chi, Quoc V Le, Denny Zhou,
et al. 2022b. Chain-of-thought prompting elicits reasoning in large language models. _Advances in Neural_
_Information Processing Systems_, 35:24824–24837.


Thomas Wolf, Lysandre Debut, Victor Sanh, Julien
Chaumond, Clement Delangue, Anthony Moi, Pierric Cistac, Tim Rault, Rémi Louf, Morgan Funtowicz,
et al. 2019. Huggingface’s transformers: State-ofthe-art natural language processing. _arXiv preprint_
_arXiv:1910.03771_ .


Prateek Yadav, Derek Tam, Leshem Choshen, Colin
Raffel, and Mohit Bansal. 2023. Ties-merging: Resolving interference when merging models. In _Thirty-_
_seventh Conference on Neural Information Process-_
_ing Systems_ .


Chengrun Yang, Xuezhi Wang, Yifeng Lu, Hanxiao Liu,
Quoc V Le, Denny Zhou, and Xinyun Chen. 2023.
Large language models as optimizers. _arXiv preprint_
_arXiv:2309.03409_ .


Yiqun Yao, Zheng Zhang, Jing Li, and Yequan
Wang. 2023. 2x faster language model pre-training
via masked structural growth. _arXiv preprint_
_arXiv:2305.02869_ .


Longhui Yu, Weisen Jiang, Han Shi, Jincheng Yu,
Zhengying Liu, Yu Zhang, James T Kwok, Zhenguo Li, Adrian Weller, and Weiyang Liu. 2023.
Metamath: Bootstrap your own mathematical questions for large language models. _arXiv preprint_
_arXiv:2309.12284_ .


Zheng Yuan, Hongyi Yuan, Chuanqi Tan, Wei Wang,
Songfang Huang, and Fei Huang. 2023. Rrhf:
Rank responses to align language models with
human feedback without tears. _arXiv preprint_
_arXiv:2304.05302_ .



Rowan Zellers, Ari Holtzman, Yonatan Bisk, Ali
Farhadi, and Yejin Choi. 2019. Hellaswag: Can a
machine really finish your sentence? In _Proceedings_
_of the 57th Annual Meeting of the Association for_
_Computational Linguistics_, pages 4791–4800.


Shengyu Zhang, Linfeng Dong, Xiaoya Li, Sen Zhang,
Xiaofei Sun, Shuhe Wang, Jiwei Li, Runyi Hu, Tianwei Zhang, Fei Wu, et al. 2023. Instruction tuning
for large language models: A survey. _arXiv preprint_
_arXiv:2308.10792_ .


Wayne Xin Zhao, Kun Zhou, Junyi Li, Tianyi Tang,
Xiaolei Wang, Yupeng Hou, Yingqian Min, Beichen
Zhang, Junjie Zhang, Zican Dong, et al. 2023. A
survey of large language models. _arXiv preprint_
_arXiv:2303.18223_ .


Kun Zhou, Yutao Zhu, Zhipeng Chen, Wentong Chen,
Wayne Xin Zhao, Xu Chen, Yankai Lin, Ji-Rong
Wen, and Jiawei Han. 2023. Don’t make your llm
an evaluation benchmark cheater. _arXiv preprint_
_arXiv:2311.01964_ .


Daniel M Ziegler, Nisan Stiennon, Jeffrey Wu, Tom B
Brown, Alec Radford, Dario Amodei, Paul Christiano, and Geoffrey Irving. 2019. Fine-tuning language models from human preferences. _arXiv_
_preprint arXiv:1909.08593_ .


