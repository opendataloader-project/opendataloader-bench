also plays an important role in error analysis (investigating the difference between the numerical approximation and the solution).

Calculating with only a finite subset of the rational numbers has many consequences. For example: a computer cannot distinguish between two polynomials of sufficiently high degree. Consequently, methods based on the main theorem of algebra (i.e. that an nth degree polynomial has exactly n complex zeros) cannot be trusted. Errors that follow from the use of finitely many digits are called n rounding n (Section 1.4).

An important aspect of numerical mathematics is the emphasis on efficiency. Contrary to ordinary mathematics, numerical mathematics considers an increase in efficiency, i.e. a decrease of the number of operations and/or amount of storage required, as an essential improvement. Progress in this aspect is of great practical importance and the end of this development has not been reached yet. Here, the creative mind will meet many challenges. On top of that, revolutions in computer architecture will overturn much conventional wisdom.

## 1.3 Why numerical mathematics?

A big advantage of numerical mathematics is that it can provide answers to problems that do not admit closed-form solutions. Consider for example the integral

$$\int_{0}^{\pi} \sqrt{1 + \cos^2 x} dx.$$

This is an expression for the arc length of one arc of the curve  $y(x) = \sin x$ , which does not have a solution in closed form. A numerical method, however, can approximate this integral in a very simple way (Chapter 5). An additional advantage is that a numerical method only uses standard function evaluations and the operations addition, subtraction, multiplication and division. Because these are exactly the operations a computer can perform, numerical mathematics and computers form a perfect combination.

An advantage of analytical methods is that the solution is given by a mathematical formula. From this, insight in the behavior and the properties of the solution can be gained. For numerical approximations, however, this is not the case. In that case, visualization tools may be used to gain insight in the behavior of the solution. Using a numerical method to draw a graph of a function is usually a more useful tool than evaluating the solution at a large number of points.

## 1.4 Rounding errors

A computer uses a finite representation of the all numbers in  $\mathbb{R}$ . These are stored in a computer in the form

$$\pm 0.d_1d_2\ldots d_n\cdot \beta^e,\tag{1.1}$$

in which, by definition,  $d_1 > 0$  and  $0 \le d_i < \beta$ . The normalization is needed in order to prevent a waste of digits and to make the representation unambiguous. We call the value in equation (1.1) a *floating point number* (representation) in which  $0.d_1d_2...d_n$  is called the *mantissa*,  $\beta$  the *base* and e (integer) the *exponent*, where L < e < U. Characteristic values for |L| and U are in the range [100, 1000], often,  $\beta = 2$  (binary representation) and n = 24 (*single* precision) or n = 53 (*double* precision). Most computers and software packages (Matlab) satisfy the IEEE-754 standard, and hence provide single-1 and double-precision<sup>2</sup> computations.

Let for  $x \in \mathbb{R}$ 

$$0.d_1 \dots d_n \cdot \beta^e \leq x < 0.d_1 d_2 \dots (d_n + 1) \cdot \beta^e,$$

 $<sup>^{1} \\ \</sup>texttt{http://en.wikipedia.org/wiki/Single-precision\_floating-point\_format} \\$ 

<sup>&</sup>lt;sup>2</sup>http://en.wikipedia.org/wiki/Double-precision\_floating-point\_format